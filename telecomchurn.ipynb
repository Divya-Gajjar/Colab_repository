{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "telecomchurn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Divya-Gajjar/Colab_repository/blob/master/telecomchurn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN0rNEqhcVf7",
        "colab_type": "code",
        "outputId": "624e9e3d-a0fa-45a5-a363-9803b4d08202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import yellowbrick\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEssoLdVdP_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"/content/telecomchurn.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZI3t-LMuuwi",
        "colab_type": "text"
      },
      "source": [
        "Preproccesing function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t61ZX_9-oi6M",
        "colab_type": "code",
        "outputId": "a4fd3306-7335-4b28-ce68-b6fde642b5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "  global df\n",
        "  print(\"\\n\\nbefore preprocessing total numbers of null values\\n\")\n",
        "  print(df.isnull().sum())\n",
        "  '''df=df.fillna(df.mean())\n",
        "  print(\"\\n\\nreplacing null numeric values with mean\\n\")\n",
        "  print(df.isnull().sum())\n",
        "  print(\"\\n\\ndroping non-numeric null values\\n\")'''\n",
        "  df = df.dropna()\n",
        "  print(df.isnull().sum())\n",
        "\n",
        "  return;\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "before preprocessing total numbers of null values\n",
            "\n",
            "CustomerID                     0\n",
            "Churn                          0\n",
            "MonthlyRevenue                25\n",
            "MonthlyMinutes                25\n",
            "TotalRecurringCharge          25\n",
            "DirectorAssistedCalls         25\n",
            "OverageMinutes                25\n",
            "RoamingCalls                  25\n",
            "PercChangeMinutes             72\n",
            "PercChangeRevenues            72\n",
            "DroppedCalls                   0\n",
            "BlockedCalls                   0\n",
            "UnansweredCalls                0\n",
            "CustomerCareCalls              0\n",
            "ThreewayCalls                  0\n",
            "ReceivedCalls                  0\n",
            "OutboundCalls                  0\n",
            "InboundCalls                   0\n",
            "PeakCallsInOut                 0\n",
            "OffPeakCallsInOut              0\n",
            "DroppedBlockedCalls            0\n",
            "CallForwardingCalls            0\n",
            "CallWaitingCalls               0\n",
            "MonthsInService                0\n",
            "UniqueSubs                     0\n",
            "ActiveSubs                     0\n",
            "ServiceArea                    8\n",
            "Handsets                       0\n",
            "HandsetModels                  0\n",
            "CurrentEquipmentDays           0\n",
            "AgeHH1                       229\n",
            "AgeHH2                       229\n",
            "ChildrenInHH                   1\n",
            "HandsetRefurbished             1\n",
            "HandsetWebCapable              1\n",
            "TruckOwner                     1\n",
            "RVOwner                        1\n",
            "Homeownership                  1\n",
            "BuysViaMailOrder               1\n",
            "RespondsToMailOffers           1\n",
            "OptOutMailings                 1\n",
            "NonUSTravel                    1\n",
            "OwnsComputer                   1\n",
            "HasCreditCard                  1\n",
            "RetentionCalls                 1\n",
            "RetentionOffersAccepted        1\n",
            "NewCellphoneUser               1\n",
            "NotNewCellphoneUser            1\n",
            "ReferralsMadeBySubscriber      1\n",
            "IncomeGroup                    1\n",
            "OwnsMotorcycle                 1\n",
            "AdjustmentsToCreditRating      1\n",
            "HandsetPrice                   1\n",
            "MadeCallToRetentionTeam        1\n",
            "CreditRating                   1\n",
            "PrizmCode                      1\n",
            "Occupation                     1\n",
            "MaritalStatus                  1\n",
            "dtype: int64\n",
            "CustomerID                   0\n",
            "Churn                        0\n",
            "MonthlyRevenue               0\n",
            "MonthlyMinutes               0\n",
            "TotalRecurringCharge         0\n",
            "DirectorAssistedCalls        0\n",
            "OverageMinutes               0\n",
            "RoamingCalls                 0\n",
            "PercChangeMinutes            0\n",
            "PercChangeRevenues           0\n",
            "DroppedCalls                 0\n",
            "BlockedCalls                 0\n",
            "UnansweredCalls              0\n",
            "CustomerCareCalls            0\n",
            "ThreewayCalls                0\n",
            "ReceivedCalls                0\n",
            "OutboundCalls                0\n",
            "InboundCalls                 0\n",
            "PeakCallsInOut               0\n",
            "OffPeakCallsInOut            0\n",
            "DroppedBlockedCalls          0\n",
            "CallForwardingCalls          0\n",
            "CallWaitingCalls             0\n",
            "MonthsInService              0\n",
            "UniqueSubs                   0\n",
            "ActiveSubs                   0\n",
            "ServiceArea                  0\n",
            "Handsets                     0\n",
            "HandsetModels                0\n",
            "CurrentEquipmentDays         0\n",
            "AgeHH1                       0\n",
            "AgeHH2                       0\n",
            "ChildrenInHH                 0\n",
            "HandsetRefurbished           0\n",
            "HandsetWebCapable            0\n",
            "TruckOwner                   0\n",
            "RVOwner                      0\n",
            "Homeownership                0\n",
            "BuysViaMailOrder             0\n",
            "RespondsToMailOffers         0\n",
            "OptOutMailings               0\n",
            "NonUSTravel                  0\n",
            "OwnsComputer                 0\n",
            "HasCreditCard                0\n",
            "RetentionCalls               0\n",
            "RetentionOffersAccepted      0\n",
            "NewCellphoneUser             0\n",
            "NotNewCellphoneUser          0\n",
            "ReferralsMadeBySubscriber    0\n",
            "IncomeGroup                  0\n",
            "OwnsMotorcycle               0\n",
            "AdjustmentsToCreditRating    0\n",
            "HandsetPrice                 0\n",
            "MadeCallToRetentionTeam      0\n",
            "CreditRating                 0\n",
            "PrizmCode                    0\n",
            "Occupation                   0\n",
            "MaritalStatus                0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdS3U77hxbxZ",
        "colab_type": "code",
        "outputId": "0f6eb47d-7d74-4f31-dc8f-a20745373a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomerID                     int64\n",
              "Churn                          int64\n",
              "MonthlyRevenue               float64\n",
              "MonthlyMinutes               float64\n",
              "TotalRecurringCharge         float64\n",
              "DirectorAssistedCalls        float64\n",
              "OverageMinutes               float64\n",
              "RoamingCalls                 float64\n",
              "PercChangeMinutes            float64\n",
              "PercChangeRevenues           float64\n",
              "DroppedCalls                 float64\n",
              "BlockedCalls                 float64\n",
              "UnansweredCalls              float64\n",
              "CustomerCareCalls            float64\n",
              "ThreewayCalls                float64\n",
              "ReceivedCalls                float64\n",
              "OutboundCalls                float64\n",
              "InboundCalls                 float64\n",
              "PeakCallsInOut               float64\n",
              "OffPeakCallsInOut            float64\n",
              "DroppedBlockedCalls          float64\n",
              "CallForwardingCalls          float64\n",
              "CallWaitingCalls             float64\n",
              "MonthsInService                int64\n",
              "UniqueSubs                     int64\n",
              "ActiveSubs                     int64\n",
              "ServiceArea                    int64\n",
              "Handsets                     float64\n",
              "HandsetModels                float64\n",
              "CurrentEquipmentDays         float64\n",
              "AgeHH1                       float64\n",
              "AgeHH2                       float64\n",
              "ChildrenInHH                   int64\n",
              "HandsetRefurbished             int64\n",
              "HandsetWebCapable              int64\n",
              "TruckOwner                     int64\n",
              "RVOwner                        int64\n",
              "Homeownership                  int64\n",
              "BuysViaMailOrder               int64\n",
              "RespondsToMailOffers           int64\n",
              "OptOutMailings                 int64\n",
              "NonUSTravel                    int64\n",
              "OwnsComputer                   int64\n",
              "HasCreditCard                  int64\n",
              "RetentionCalls                 int64\n",
              "RetentionOffersAccepted        int64\n",
              "NewCellphoneUser               int64\n",
              "NotNewCellphoneUser            int64\n",
              "ReferralsMadeBySubscriber      int64\n",
              "IncomeGroup                    int64\n",
              "OwnsMotorcycle                 int64\n",
              "AdjustmentsToCreditRating      int64\n",
              "HandsetPrice                   int64\n",
              "MadeCallToRetentionTeam        int64\n",
              "CreditRating                   int64\n",
              "PrizmCode                      int64\n",
              "Occupation                     int64\n",
              "MaritalStatus                  int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LlC1RZwwUSo",
        "colab_type": "text"
      },
      "source": [
        "label encoding for the object varibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lnE_1T8S0-o",
        "colab_type": "code",
        "outputId": "ef28097f-a9b1-4c3f-ab6b-57883ec7218a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CustomerID', 'Churn', 'MonthlyRevenue', 'MonthlyMinutes',\n",
              "       'TotalRecurringCharge', 'DirectorAssistedCalls', 'OverageMinutes',\n",
              "       'RoamingCalls', 'PercChangeMinutes', 'PercChangeRevenues',\n",
              "       'DroppedCalls', 'BlockedCalls', 'UnansweredCalls', 'CustomerCareCalls',\n",
              "       'ThreewayCalls', 'ReceivedCalls', 'OutboundCalls', 'InboundCalls',\n",
              "       'PeakCallsInOut', 'OffPeakCallsInOut', 'DroppedBlockedCalls',\n",
              "       'CallForwardingCalls', 'CallWaitingCalls', 'MonthsInService',\n",
              "       'UniqueSubs', 'ActiveSubs', 'ServiceArea', 'Handsets', 'HandsetModels',\n",
              "       'CurrentEquipmentDays', 'AgeHH1', 'AgeHH2', 'ChildrenInHH',\n",
              "       'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', 'RVOwner',\n",
              "       'Homeownership', 'BuysViaMailOrder', 'RespondsToMailOffers',\n",
              "       'OptOutMailings', 'NonUSTravel', 'OwnsComputer', 'HasCreditCard',\n",
              "       'RetentionCalls', 'RetentionOffersAccepted', 'NewCellphoneUser',\n",
              "       'NotNewCellphoneUser', 'ReferralsMadeBySubscriber', 'IncomeGroup',\n",
              "       'OwnsMotorcycle', 'AdjustmentsToCreditRating', 'HandsetPrice',\n",
              "       'MadeCallToRetentionTeam', 'CreditRating', 'PrizmCode', 'Occupation',\n",
              "       'MaritalStatus'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRNk4wI4wS_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYFk1OmV7zDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['ServiceArea'] = df['ServiceArea'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTSgqnJq0Tqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['ServiceArea']= le.fit_transform(df['ServiceArea'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go-6-3y90NHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Churn']= le.fit_transform(df['Churn']) \n",
        "df['ChildrenInHH']= le.fit_transform(df['ChildrenInHH']) \n",
        "df['HandsetRefurbished']= le.fit_transform(df['HandsetRefurbished']) \n",
        "df['HandsetWebCapable']= le.fit_transform(df['HandsetWebCapable'])  \n",
        "df['TruckOwner']= le.fit_transform(df['TruckOwner'])  \n",
        "df['RVOwner']= le.fit_transform(df['RVOwner'])  \n",
        "df['Homeownership']= le.fit_transform(df['Homeownership'])  \n",
        "df['BuysViaMailOrder']= le.fit_transform(df['BuysViaMailOrder'])  \n",
        "df['RespondsToMailOffers']= le.fit_transform(df['RespondsToMailOffers'])\n",
        "df['OptOutMailings']= le.fit_transform(df['OptOutMailings'])   \n",
        "df['NonUSTravel']= le.fit_transform(df['NonUSTravel'])   \n",
        "df['OwnsComputer']= le.fit_transform(df['OwnsComputer'])  \n",
        "df['HasCreditCard']= le.fit_transform(df['HasCreditCard']) \n",
        "df['NewCellphoneUser']= le.fit_transform(df['NewCellphoneUser'])\n",
        "df['NotNewCellphoneUser']= le.fit_transform(df['NotNewCellphoneUser'])\n",
        "df['OwnsMotorcycle']= le.fit_transform(df['OwnsMotorcycle'])\n",
        "df['HandsetPrice']= le.fit_transform(df['HandsetPrice'])\n",
        "df['MadeCallToRetentionTeam']= le.fit_transform(df['MadeCallToRetentionTeam'])\n",
        "df['CreditRating']= le.fit_transform(df['CreditRating'])\n",
        "df['PrizmCode']= le.fit_transform(df['PrizmCode'])\n",
        "df['Occupation']= le.fit_transform(df['Occupation'])\n",
        "df['MaritalStatus']= le.fit_transform(df['MaritalStatus'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hHSAKUd0gMZ",
        "colab_type": "code",
        "outputId": "0e591c47-7237-43f4-a199-c75f5645ad4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Churn</th>\n",
              "      <th>MonthlyRevenue</th>\n",
              "      <th>MonthlyMinutes</th>\n",
              "      <th>TotalRecurringCharge</th>\n",
              "      <th>DirectorAssistedCalls</th>\n",
              "      <th>OverageMinutes</th>\n",
              "      <th>RoamingCalls</th>\n",
              "      <th>PercChangeMinutes</th>\n",
              "      <th>PercChangeRevenues</th>\n",
              "      <th>DroppedCalls</th>\n",
              "      <th>BlockedCalls</th>\n",
              "      <th>UnansweredCalls</th>\n",
              "      <th>CustomerCareCalls</th>\n",
              "      <th>ThreewayCalls</th>\n",
              "      <th>ReceivedCalls</th>\n",
              "      <th>OutboundCalls</th>\n",
              "      <th>InboundCalls</th>\n",
              "      <th>PeakCallsInOut</th>\n",
              "      <th>OffPeakCallsInOut</th>\n",
              "      <th>DroppedBlockedCalls</th>\n",
              "      <th>CallForwardingCalls</th>\n",
              "      <th>CallWaitingCalls</th>\n",
              "      <th>MonthsInService</th>\n",
              "      <th>UniqueSubs</th>\n",
              "      <th>ActiveSubs</th>\n",
              "      <th>ServiceArea</th>\n",
              "      <th>Handsets</th>\n",
              "      <th>HandsetModels</th>\n",
              "      <th>CurrentEquipmentDays</th>\n",
              "      <th>AgeHH1</th>\n",
              "      <th>AgeHH2</th>\n",
              "      <th>ChildrenInHH</th>\n",
              "      <th>HandsetRefurbished</th>\n",
              "      <th>HandsetWebCapable</th>\n",
              "      <th>TruckOwner</th>\n",
              "      <th>RVOwner</th>\n",
              "      <th>Homeownership</th>\n",
              "      <th>BuysViaMailOrder</th>\n",
              "      <th>RespondsToMailOffers</th>\n",
              "      <th>OptOutMailings</th>\n",
              "      <th>NonUSTravel</th>\n",
              "      <th>OwnsComputer</th>\n",
              "      <th>HasCreditCard</th>\n",
              "      <th>RetentionCalls</th>\n",
              "      <th>RetentionOffersAccepted</th>\n",
              "      <th>NewCellphoneUser</th>\n",
              "      <th>NotNewCellphoneUser</th>\n",
              "      <th>ReferralsMadeBySubscriber</th>\n",
              "      <th>IncomeGroup</th>\n",
              "      <th>OwnsMotorcycle</th>\n",
              "      <th>AdjustmentsToCreditRating</th>\n",
              "      <th>HandsetPrice</th>\n",
              "      <th>MadeCallToRetentionTeam</th>\n",
              "      <th>CreditRating</th>\n",
              "      <th>PrizmCode</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>MaritalStatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3000002</td>\n",
              "      <td>1</td>\n",
              "      <td>24.00</td>\n",
              "      <td>219.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-157.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>658</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>361.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3000010</td>\n",
              "      <td>1</td>\n",
              "      <td>16.99</td>\n",
              "      <td>10.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>610</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1504.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3000014</td>\n",
              "      <td>0</td>\n",
              "      <td>38.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>352</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1812.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3000022</td>\n",
              "      <td>0</td>\n",
              "      <td>82.28</td>\n",
              "      <td>1312.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>8.1</td>\n",
              "      <td>52.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>200.3</td>\n",
              "      <td>370.3</td>\n",
              "      <td>147.0</td>\n",
              "      <td>555.7</td>\n",
              "      <td>303.7</td>\n",
              "      <td>59.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.7</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>610</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>458.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3000026</td>\n",
              "      <td>1</td>\n",
              "      <td>17.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>563</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>852.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CustomerID  Churn  MonthlyRevenue  ...  PrizmCode  Occupation  MaritalStatus\n",
              "0     3000002      1           24.00  ...          2           4              0\n",
              "1     3000010      1           16.99  ...          2           4              2\n",
              "2     3000014      0           38.00  ...          3           1              2\n",
              "3     3000022      0           82.28  ...          0           3              0\n",
              "4     3000026      1           17.14  ...          0           4              2\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAcdaK8Nvsa9",
        "colab_type": "text"
      },
      "source": [
        "selection of x and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w4cqVwAe9ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['CustomerID', 'MonthlyRevenue', 'MonthlyMinutes',\n",
        "       'TotalRecurringCharge', 'DirectorAssistedCalls', 'OverageMinutes',\n",
        "       'RoamingCalls', 'PercChangeMinutes', 'PercChangeRevenues',\n",
        "       'DroppedCalls', 'BlockedCalls', 'UnansweredCalls', 'CustomerCareCalls',\n",
        "       'ThreewayCalls', 'ReceivedCalls', 'OutboundCalls', 'InboundCalls',\n",
        "       'PeakCallsInOut', 'OffPeakCallsInOut', 'DroppedBlockedCalls',\n",
        "       'CallForwardingCalls', 'CallWaitingCalls', 'MonthsInService',\n",
        "       'UniqueSubs', 'ActiveSubs', 'ServiceArea', 'Handsets', 'HandsetModels',\n",
        "       'CurrentEquipmentDays', 'AgeHH1', 'AgeHH2', 'ChildrenInHH',\n",
        "       'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', 'RVOwner',\n",
        "       'Homeownership', 'BuysViaMailOrder', 'RespondsToMailOffers',\n",
        "       'OptOutMailings', 'NonUSTravel', 'OwnsComputer', 'HasCreditCard',\n",
        "       'RetentionCalls', 'RetentionOffersAccepted', 'NewCellphoneUser',\n",
        "       'NotNewCellphoneUser', 'ReferralsMadeBySubscriber', 'IncomeGroup',\n",
        "       'OwnsMotorcycle', 'AdjustmentsToCreditRating', 'HandsetPrice',\n",
        "       'MadeCallToRetentionTeam', 'CreditRating', 'PrizmCode', 'Occupation',\n",
        "       'MaritalStatus']]\n",
        "y = df[['Churn']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwevXrEGAMP7",
        "colab_type": "text"
      },
      "source": [
        "Random forest model for feature engineering using all the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RAnG_5uwvE_P",
        "outputId": "7e8aaed6-4e82-41ba-e99f-b55575483d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "def main():\n",
        "  global clf\n",
        "  from sklearn.model_selection import train_test_split  \n",
        "  xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(xtrain,ytrain)\n",
        "  print(\"Randome Forest\")\n",
        "  print(\"train score\",clf.score(xtrain, ytrain))\n",
        "  print(\"test score\",clf.score(xtest, ytest))\n",
        "  y_pred = clf.predict(xtest)\n",
        "  print(\"prediction of y\",y_pred)\n",
        "  from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix\n",
        "  print(\"precision, recall, f1-score and supports instead of averaging\",  precision_recall_fscore_support(ytest, y_pred, average=None))\n",
        "  print(classification_report(ytest,y_pred))\n",
        "  print(confusion_matrix(ytest,y_pred))\n",
        "  return; \n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Randome Forest\n",
            "train score 1.0\n",
            "test score 0.7100127280441239\n",
            "prediction of y [0 0 0 ... 0 0 0]\n",
            "precision, recall, f1-score and supports instead of averaging (array([0.719148, 0.45    ]), array([0.97383289, 0.05329386]), array([0.82733359, 0.09530113]), array([3363, 1351]))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83      3363\n",
            "           1       0.45      0.05      0.10      1351\n",
            "\n",
            "    accuracy                           0.71      4714\n",
            "   macro avg       0.58      0.51      0.46      4714\n",
            "weighted avg       0.64      0.71      0.62      4714\n",
            "\n",
            "[[3275   88]\n",
            " [1279   72]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ-0JV-8u1kP",
        "colab_type": "text"
      },
      "source": [
        "Feature engineering function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhnQxQrKaxz9",
        "colab_type": "code",
        "outputId": "c76abbba-543d-4dd9-9667-74a9a4ddc19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def feature_engineering():\n",
        "  feat_importances = pd.Series(clf.feature_importances_, index=x.columns)\n",
        "  feat_importances.nlargest(20).plot(kind='barh')\n",
        "  plt.show()\n",
        "  \n",
        "  from sklearn.feature_selection import RFE\n",
        "  selector = RFE(clf, 5)\n",
        "  selector = selector.fit(x,y)\n",
        "  l1 = selector.ranking_\n",
        "  l2 = x.columns\n",
        "  for i in zip(l1,l2):\n",
        "    print(i)\n",
        "  \n",
        "\n",
        "  return;\n",
        "feature_engineering()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAFKCAYAAAD7QJ6iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgih1aTZEUIIIYRWk2ZHCCGEEFrt/wPD2a9gxsTfFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 'CustomerID')\n",
            "(1, 'MonthlyRevenue')\n",
            "(1, 'MonthlyMinutes')\n",
            "(8, 'TotalRecurringCharge')\n",
            "(19, 'DirectorAssistedCalls')\n",
            "(13, 'OverageMinutes')\n",
            "(18, 'RoamingCalls')\n",
            "(1, 'PercChangeMinutes')\n",
            "(2, 'PercChangeRevenues')\n",
            "(14, 'DroppedCalls')\n",
            "(16, 'BlockedCalls')\n",
            "(9, 'UnansweredCalls')\n",
            "(20, 'CustomerCareCalls')\n",
            "(29, 'ThreewayCalls')\n",
            "(7, 'ReceivedCalls')\n",
            "(11, 'OutboundCalls')\n",
            "(15, 'InboundCalls')\n",
            "(4, 'PeakCallsInOut')\n",
            "(6, 'OffPeakCallsInOut')\n",
            "(10, 'DroppedBlockedCalls')\n",
            "(53, 'CallForwardingCalls')\n",
            "(23, 'CallWaitingCalls')\n",
            "(5, 'MonthsInService')\n",
            "(25, 'UniqueSubs')\n",
            "(33, 'ActiveSubs')\n",
            "(3, 'ServiceArea')\n",
            "(26, 'Handsets')\n",
            "(31, 'HandsetModels')\n",
            "(1, 'CurrentEquipmentDays')\n",
            "(12, 'AgeHH1')\n",
            "(17, 'AgeHH2')\n",
            "(39, 'ChildrenInHH')\n",
            "(34, 'HandsetRefurbished')\n",
            "(36, 'HandsetWebCapable')\n",
            "(44, 'TruckOwner')\n",
            "(46, 'RVOwner')\n",
            "(40, 'Homeownership')\n",
            "(41, 'BuysViaMailOrder')\n",
            "(37, 'RespondsToMailOffers')\n",
            "(52, 'OptOutMailings')\n",
            "(48, 'NonUSTravel')\n",
            "(43, 'OwnsComputer')\n",
            "(45, 'HasCreditCard')\n",
            "(30, 'RetentionCalls')\n",
            "(50, 'RetentionOffersAccepted')\n",
            "(38, 'NewCellphoneUser')\n",
            "(42, 'NotNewCellphoneUser')\n",
            "(47, 'ReferralsMadeBySubscriber')\n",
            "(21, 'IncomeGroup')\n",
            "(51, 'OwnsMotorcycle')\n",
            "(49, 'AdjustmentsToCreditRating')\n",
            "(24, 'HandsetPrice')\n",
            "(35, 'MadeCallToRetentionTeam')\n",
            "(22, 'CreditRating')\n",
            "(27, 'PrizmCode')\n",
            "(28, 'Occupation')\n",
            "(32, 'MaritalStatus')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkqTC-G0v0Xl",
        "colab_type": "text"
      },
      "source": [
        "selection of x using feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz4Qo07SkCGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=df[['CustomerID','MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','PercChangeRevenues', 'PeakCallsInOut', 'OffPeakCallsInOut', 'MonthsInService', 'ServiceArea', 'CurrentEquipmentDays']]\n",
        "y = df[['Churn']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5VyINIYwrC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=df[['CustomerID','MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','CurrentEquipmentDays']]\n",
        "y=df[['Churn']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myC9EYLJJBTk",
        "colab_type": "code",
        "outputId": "b6f0b344-f405-41a0-9512-1fd6e810fb80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "df.columns\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CustomerID', 'Churn', 'MonthlyRevenue', 'MonthlyMinutes',\n",
              "       'TotalRecurringCharge', 'DirectorAssistedCalls', 'OverageMinutes',\n",
              "       'RoamingCalls', 'PercChangeMinutes', 'PercChangeRevenues',\n",
              "       'DroppedCalls', 'BlockedCalls', 'UnansweredCalls', 'CustomerCareCalls',\n",
              "       'ThreewayCalls', 'ReceivedCalls', 'OutboundCalls', 'InboundCalls',\n",
              "       'PeakCallsInOut', 'OffPeakCallsInOut', 'DroppedBlockedCalls',\n",
              "       'CallForwardingCalls', 'CallWaitingCalls', 'MonthsInService',\n",
              "       'UniqueSubs', 'ActiveSubs', 'ServiceArea', 'Handsets', 'HandsetModels',\n",
              "       'CurrentEquipmentDays', 'AgeHH1', 'AgeHH2', 'ChildrenInHH',\n",
              "       'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', 'RVOwner',\n",
              "       'Homeownership', 'BuysViaMailOrder', 'RespondsToMailOffers',\n",
              "       'OptOutMailings', 'NonUSTravel', 'OwnsComputer', 'HasCreditCard',\n",
              "       'RetentionCalls', 'RetentionOffersAccepted', 'NewCellphoneUser',\n",
              "       'NotNewCellphoneUser', 'ReferralsMadeBySubscriber', 'IncomeGroup',\n",
              "       'OwnsMotorcycle', 'AdjustmentsToCreditRating', 'HandsetPrice',\n",
              "       'MadeCallToRetentionTeam', 'CreditRating', 'PrizmCode', 'Occupation',\n",
              "       'MaritalStatus'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmfKeFC1I2gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=df[['MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','PercChangeRevenues', 'PeakCallsInOut', 'OffPeakCallsInOut', 'MonthsInService', 'ServiceArea', 'CurrentEquipmentDays', 'MadeCallToRetentionTeam', 'RetentionCalls', 'RetentionOffersAccepted','CallForwardingCalls','CustomerCareCalls','UnansweredCalls','DroppedCalls','TotalRecurringCharge','CreditRating']]\n",
        "y = df[['Churn']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BqmdIzzl7kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['MonthlyRevenue','MonthlyMinutes','TotalRecurringCharge','OverageMinutes','UnansweredCalls','DroppedCalls','OutboundCalls','AgeHH1','PercChangeMinutes','PercChangeRevenues','ReceivedCalls','PeakCallsInOut','OffPeakCallsInOut','MonthsInService','ServiceArea','CurrentEquipmentDays']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDLfGjUN-kap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['CustomerID','MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','PercChangeRevenues', 'PeakCallsInOut', 'OffPeakCallsInOut', 'MonthsInService', 'ServiceArea', 'CurrentEquipmentDays','DroppedCalls', 'UnansweredCalls', 'CustomerCareCalls', 'RoamingCalls', 'CurrentEquipmentDays',  'Occupation',\n",
        "       'MaritalStatus']]\n",
        "y = df[['Churn']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpk8RSBwW5aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['MadeCallToRetentionTeam','RetentionCalls', 'RetentionOffersAccepted', 'HandsetWebCapable', 'CurrentEquipmentDays', 'CallForwardingCalls', 'CustomerID', 'MonthsInService', 'ServiceArea', 'TotalRecurringCharge']]\n",
        "y=df[['Churn']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm6BKk88XCQI",
        "colab_type": "code",
        "outputId": "6906cd65-af74-4fbc-ed1b-4b34f25828ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CustomerID', 'Churn', 'MonthlyRevenue', 'MonthlyMinutes',\n",
              "       'TotalRecurringCharge', 'DirectorAssistedCalls', 'OverageMinutes',\n",
              "       'RoamingCalls', 'PercChangeMinutes', 'PercChangeRevenues',\n",
              "       'DroppedCalls', 'BlockedCalls', 'UnansweredCalls', 'CustomerCareCalls',\n",
              "       'ThreewayCalls', 'ReceivedCalls', 'OutboundCalls', 'InboundCalls',\n",
              "       'PeakCallsInOut', 'OffPeakCallsInOut', 'DroppedBlockedCalls',\n",
              "       'CallForwardingCalls', 'CallWaitingCalls', 'MonthsInService',\n",
              "       'UniqueSubs', 'ActiveSubs', 'ServiceArea', 'Handsets', 'HandsetModels',\n",
              "       'CurrentEquipmentDays', 'AgeHH1', 'AgeHH2', 'ChildrenInHH',\n",
              "       'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', 'RVOwner',\n",
              "       'Homeownership', 'BuysViaMailOrder', 'RespondsToMailOffers',\n",
              "       'OptOutMailings', 'NonUSTravel', 'OwnsComputer', 'HasCreditCard',\n",
              "       'RetentionCalls', 'RetentionOffersAccepted', 'NewCellphoneUser',\n",
              "       'NotNewCellphoneUser', 'ReferralsMadeBySubscriber', 'IncomeGroup',\n",
              "       'OwnsMotorcycle', 'AdjustmentsToCreditRating', 'HandsetPrice',\n",
              "       'MadeCallToRetentionTeam', 'CreditRating', 'PrizmCode', 'Occupation',\n",
              "       'MaritalStatus'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFPOxccBv7_9",
        "colab_type": "text"
      },
      "source": [
        "model after feature engineering usinng for loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRZI_Rrslikr",
        "colab_type": "code",
        "outputId": "f936b270-8ba9-43cf-abc0-adc6b9a7e3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "source": [
        "def main():\n",
        "  scorelist_testing=[]\n",
        "  scorelist_training=[]\n",
        "  iteration=[]\n",
        "  for i in range (0,5):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier(max_depth=15, random_state=0, n_estimators=100)\n",
        "    clf.fit(xtrain,ytrain)\n",
        "    scorelist_training.append(clf.score(xtrain,ytrain))\n",
        "    scorelist_testing.append(clf.score(xtest,ytest))\n",
        "    print(clf.score(xtrain,ytrain))   \n",
        "    print(clf.score(xtest,ytest))\n",
        "    iteration.append(i)\n",
        "  plt.plot(iteration,scorelist_training,label='Training_score')\n",
        "  plt.plot(iteration,scorelist_testing,label='Testing_score')\n",
        "  plt.legend()\n",
        "\n",
        "  return;\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8335479896964946\n",
            "0.7201933755798001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8288722141337216\n",
            "0.7181028287711505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.828620226229141\n",
            "0.7182334879466911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8316720797401724\n",
            "0.7146403606193245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8277802665472057\n",
            "0.7164042594891227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEM4AAFgM4QwAgMUQzgAAWMz/A3rIbIlQCHoIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0warZkc9RIk",
        "colab_type": "text"
      },
      "source": [
        "from here all the processing into dataset and model starts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59MIuY8gQ5dX",
        "colab_type": "code",
        "outputId": "9e426590-a64e-4299-b89c-652b31d51d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x=df[['CustomerID','MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','PercChangeRevenues', 'PeakCallsInOut', 'OffPeakCallsInOut', 'MonthsInService', 'ServiceArea', 'CurrentEquipmentDays']]\n",
        "y = df[['Churn']]\n",
        "for split in[2,3,4,5,6,7,8,9,10,12,14,16,18,20]:\n",
        "  from sklearn.model_selection import train_test_split  \n",
        "  xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  clf = RandomForestClassifier(max_depth=15, random_state=0,n_estimators=1000,min_samples_split=split)\n",
        "  clf.fit(xtrain,ytrain)\n",
        "  print(\"  split= \",split,\"\\n\")\n",
        "  print(\"train score\",clf.score(xtrain, ytrain))\n",
        "  print('clf.score',clf.score(xtest, ytest),'\\n')\n",
        "  y_pred = clf.predict(xtest)\n",
        "  from sklearn.metrics import precision_recall_fscore_support\n",
        "  print('precision_recall_fscore_support\\n',precision_recall_fscore_support(ytest, y_pred, average=None),'\\n')\n",
        "  from sklearn.metrics import classification_report\n",
        "  print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  2 \n",
            "\n",
            "train score 0.8328200246388173\n",
            "clf.score 0.7217612856862873 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72877423, 0.5648855 ]), array([0.97400347, 0.08517495]), array([0.83373024, 0.14802961]), array([10963,  4344])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83     10963\n",
            "           1       0.56      0.09      0.15      4344\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10678   285]\n",
            " [ 3974   370]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  3 \n",
            "\n",
            "train score 0.8268003135849479\n",
            "clf.score 0.7184948062977723 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72759046, 0.53286713]), array([0.9695005 , 0.08746556]), array([0.83130408, 0.15026622]), array([10951,  4356])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83     10951\n",
            "           1       0.53      0.09      0.15      4356\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.63      0.53      0.49     15307\n",
            "weighted avg       0.67      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10617   334]\n",
            " [ 3975   381]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  4 \n",
            "\n",
            "train score 0.822292529958562\n",
            "clf.score 0.7218266152740577 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72956706, 0.55685131]), array([0.97229058, 0.08809963]), array([0.83361988, 0.15213063]), array([10971,  4336])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83     10971\n",
            "           1       0.56      0.09      0.15      4336\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.64      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10667   304]\n",
            " [ 3954   382]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  5 \n",
            "\n",
            "train score 0.8159928323440475\n",
            "clf.score 0.7173188737179068 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72282535, 0.57469244]), array([0.97778798, 0.07411605]), array([0.83119416, 0.13129894]), array([10895,  4412])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10895\n",
            "           1       0.57      0.07      0.13      4412\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.48     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10653   242]\n",
            " [ 4085   327]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  6 \n",
            "\n",
            "train score 0.8177567476761115\n",
            "clf.score 0.7145097014437839 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72119061, 0.5660091 ]), array([0.97364055, 0.08368858]), array([0.82861401, 0.14581704]), array([10850,  4457])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83     10850\n",
            "           1       0.57      0.08      0.15      4457\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.64      0.53      0.49     15307\n",
            "weighted avg       0.68      0.71      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10564   286]\n",
            " [ 4084   373]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  7 \n",
            "\n",
            "train score 0.8087971777354687\n",
            "clf.score 0.7149016789704057 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72093656, 0.57073171]), array([0.97568165, 0.07885868]), array([0.82918428, 0.13857086]), array([10856,  4451])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10856\n",
            "           1       0.57      0.08      0.14      4451\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.65      0.53      0.48     15307\n",
            "weighted avg       0.68      0.71      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10592   264]\n",
            " [ 4100   351]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  8 \n",
            "\n",
            "train score 0.8070332624034047\n",
            "clf.score 0.7186254654733129 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72410745, 0.58471761]), array([0.97706001, 0.0798367 ]), array([0.83177753, 0.14049092]), array([10898,  4409])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10898\n",
            "           1       0.58      0.08      0.14      4409\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10648   250]\n",
            " [ 4057   352]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  9 \n",
            "\n",
            "train score 0.8031134505543734\n",
            "clf.score 0.7219572744495982 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72784638, 0.56942004]), array([0.97767043, 0.07474048]), array([0.8344613 , 0.13213703]), array([10972,  4335])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.83     10972\n",
            "           1       0.57      0.07      0.13      4335\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.48     15307\n",
            "weighted avg       0.68      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10727   245]\n",
            " [ 4011   324]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  10 \n",
            "\n",
            "train score 0.8001735916675999\n",
            "clf.score 0.7194747501143268 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72534587, 0.58359621]), array([0.97579536, 0.08409091]), array([0.83213448, 0.1470004 ]), array([10907,  4400])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.83     10907\n",
            "           1       0.58      0.08      0.15      4400\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10643   264]\n",
            " [ 4030   370]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  12 \n",
            "\n",
            "train score 0.7952738268563109\n",
            "clf.score 0.7206506826941922 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72689561, 0.56810631]), array([0.97625354, 0.07847637]), array([0.83332034, 0.13790323]), array([10949,  4358])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.83     10949\n",
            "           1       0.57      0.08      0.14      4358\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10689   260]\n",
            " [ 4016   342]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  14 \n",
            "\n",
            "train score 0.7884701534326353\n",
            "clf.score 0.727967596524466 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.73381001, 0.59003215]), array([0.97688333, 0.08582788]), array([0.83807746, 0.14985708]), array([11031,  4276])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.84     11031\n",
            "           1       0.59      0.09      0.15      4276\n",
            "\n",
            "    accuracy                           0.73     15307\n",
            "   macro avg       0.66      0.53      0.49     15307\n",
            "weighted avg       0.69      0.73      0.65     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10776   255]\n",
            " [ 3909   367]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  16 \n",
            "\n",
            "train score 0.7910740284466345\n",
            "clf.score 0.717122884954596 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72614393, 0.5369863 ]), array([0.96905612, 0.08941606]), array([0.83019608, 0.15330465]), array([10923,  4384])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83     10923\n",
            "           1       0.54      0.09      0.15      4384\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.63      0.53      0.49     15307\n",
            "weighted avg       0.67      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10585   338]\n",
            " [ 3992   392]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  18 \n",
            "\n",
            "train score 0.782842423563669\n",
            "clf.score 0.7165349186646632 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72122449, 0.6029654 ]), array([0.97777368, 0.08198925]), array([0.83012959, 0.14435023]), array([10843,  4464])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10843\n",
            "           1       0.60      0.08      0.14      4464\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.66      0.53      0.49     15307\n",
            "weighted avg       0.69      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10602   241]\n",
            " [ 4098   366]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  split=  20 \n",
            "\n",
            "train score 0.7795105834919924\n",
            "clf.score 0.7186254654733129 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72545541, 0.56461538]), array([0.97407475, 0.08358005]), array([0.83158018, 0.14560603]), array([10916,  4391])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83     10916\n",
            "           1       0.56      0.08      0.15      4391\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10633   283]\n",
            " [ 4024   367]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27YChB2CbN6",
        "colab_type": "code",
        "outputId": "a3c2f409-1204-47c6-8de8-66fe3de08009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x=df[['CustomerID','MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','PercChangeRevenues', 'PeakCallsInOut', 'OffPeakCallsInOut', 'MonthsInService', 'ServiceArea', 'CurrentEquipmentDays']]\n",
        "y = df[['Churn']]\n",
        "for estimator in[1000,1500,2000,2500,3000]:\n",
        "  for i in range (0,3):\n",
        "    from sklearn.model_selection import train_test_split  \n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier(max_depth=15, random_state=0,n_estimators=estimator,min_samples_split=4)\n",
        "    clf.fit(xtrain,ytrain)\n",
        "    print(\"  estimator= \",estimator,\"\\n\")\n",
        "    print(\"train score\",clf.score(xtrain, ytrain))\n",
        "    print('clf.score',clf.score(xtest, ytest),'\\n')\n",
        "    y_pred = clf.predict(xtest)\n",
        "    from sklearn.metrics import classification_report\n",
        "    print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  1000 \n",
            "\n",
            "train score 0.8208365998432076\n",
            "clf.score 0.7129417913372966 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83     10837\n",
            "           1       0.56      0.08      0.14      4470\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.64      0.53      0.48     15307\n",
            "weighted avg       0.67      0.71      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10558   279]\n",
            " [ 4115   355]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  1000 \n",
            "\n",
            "train score 0.8216205622130138\n",
            "clf.score 0.7158816227869602 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83     10912\n",
            "           1       0.53      0.08      0.15      4395\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.63      0.53      0.49     15307\n",
            "weighted avg       0.67      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10588   324]\n",
            " [ 4025   370]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  1000 \n",
            "\n",
            "train score 0.8207246052189495\n",
            "clf.score 0.7197360684654079 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.83     10943\n",
            "           1       0.56      0.08      0.14      4364\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.64      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10673   270]\n",
            " [ 4020   344]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  1500 \n",
            "\n",
            "train score 0.822516519207078\n",
            "clf.score 0.7167962370157445 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83     10915\n",
            "           1       0.54      0.08      0.14      4392\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.63      0.53      0.49     15307\n",
            "weighted avg       0.67      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10607   308]\n",
            " [ 4027   365]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  1500 \n",
            "\n",
            "train score 0.8214525702766268\n",
            "clf.score 0.7174495328934475 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10869\n",
            "           1       0.59      0.09      0.15      4438\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.66      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10602   267]\n",
            " [ 4058   380]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  1500 \n",
            "\n",
            "train score 0.8206686079068205\n",
            "clf.score 0.7156856340236493 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10864\n",
            "           1       0.58      0.08      0.13      4443\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.48     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10616   248]\n",
            " [ 4104   339]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  2000 \n",
            "\n",
            "train score 0.8236644641057229\n",
            "clf.score 0.7141177239171621 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10826\n",
            "           1       0.59      0.08      0.14      4481\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.65      0.53      0.48     15307\n",
            "weighted avg       0.68      0.71      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10584   242]\n",
            " [ 4134   347]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  2000 \n",
            "\n",
            "train score 0.8216485608690783\n",
            "clf.score 0.7159469523747305 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10848\n",
            "           1       0.59      0.08      0.14      4459\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.66      0.53      0.48     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10610   238]\n",
            " [ 4110   349]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  2000 \n",
            "\n",
            "train score 0.8196606562884982\n",
            "clf.score 0.718429476710002 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10874\n",
            "           1       0.61      0.08      0.14      4433\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.66      0.53      0.49     15307\n",
            "weighted avg       0.69      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10646   228]\n",
            " [ 4082   351]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  2500 \n",
            "\n",
            "train score 0.8214805689326913\n",
            "clf.score 0.7200627164042595 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83     10927\n",
            "           1       0.57      0.08      0.15      4380\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10650   277]\n",
            " [ 4008   372]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  2500 \n",
            "\n",
            "train score 0.8199406428491433\n",
            "clf.score 0.7164042594891227 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10879\n",
            "           1       0.57      0.08      0.14      4428\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.48     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10622   257]\n",
            " [ 4084   344]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  2500 \n",
            "\n",
            "train score 0.8203606226901109\n",
            "clf.score 0.7179721695956098 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10886\n",
            "           1       0.59      0.08      0.14      4421\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.66      0.53      0.49     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10639   247]\n",
            " [ 4070   351]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  3000 \n",
            "\n",
            "train score 0.8197726509127562\n",
            "clf.score 0.7227412295028418 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.83     10965\n",
            "           1       0.58      0.08      0.15      4342\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.69      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10697   268]\n",
            " [ 3976   366]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  3000 \n",
            "\n",
            "train score 0.8235244708254004\n",
            "clf.score 0.7128764617495263 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83     10813\n",
            "           1       0.57      0.09      0.15      4494\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.71      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10524   289]\n",
            " [ 4106   388]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  estimator=  3000 \n",
            "\n",
            "train score 0.820808601187143\n",
            "clf.score 0.7162082707258117 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83     10877\n",
            "           1       0.57      0.08      0.13      4430\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.65      0.53      0.48     15307\n",
            "weighted avg       0.68      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10628   249]\n",
            " [ 4095   335]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV2UaWMfyD9U",
        "colab_type": "text"
      },
      "source": [
        "grid search cv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxsBQKyzTaVI",
        "colab_type": "code",
        "outputId": "375a1ed0-58e7-4399-c5f3-15abff5288a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  x=df[['MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','PercChangeRevenues', 'PeakCallsInOut', 'OffPeakCallsInOut', 'MonthsInService', 'ServiceArea', 'CurrentEquipmentDays']]\n",
        "  y = df[['Churn']]\n",
        "  for i in range (0,5):\n",
        "    from sklearn.model_selection import train_test_split  \n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,shuffle=True,random_state=50)\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier(max_depth=15, n_estimators=100,min_samples_split=10, min_samples_leaf=3,bootstrap=True)\n",
        "    clf.fit(xtrain,ytrain)\n",
        "    print(\"train score\",clf.score(xtrain, ytrain))\n",
        "    print('clf.score',clf.score(xtest, ytest),'\\n')\n",
        "    y_pred = clf.predict(xtest)\n",
        "    from sklearn.metrics import classification_report\n",
        "    print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.7981730168644597\n",
            "clf.score 0.7042473454091193 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.98      0.82      2236\n",
            "           1       0.58      0.07      0.13       966\n",
            "\n",
            "    accuracy                           0.70      3202\n",
            "   macro avg       0.65      0.52      0.47      3202\n",
            "weighted avg       0.67      0.70      0.61      3202\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[2187   49]\n",
            " [ 898   68]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.7966895690193629\n",
            "clf.score 0.7020612117426608 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.97      0.82      2236\n",
            "           1       0.55      0.07      0.13       966\n",
            "\n",
            "    accuracy                           0.70      3202\n",
            "   macro avg       0.63      0.52      0.47      3202\n",
            "weighted avg       0.66      0.70      0.61      3202\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[2179   57]\n",
            " [ 897   69]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.7973141786383511\n",
            "clf.score 0.7026858213616489 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.98      0.82      2236\n",
            "           1       0.56      0.07      0.12       966\n",
            "\n",
            "    accuracy                           0.70      3202\n",
            "   macro avg       0.63      0.52      0.47      3202\n",
            "weighted avg       0.66      0.70      0.61      3202\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[2183   53]\n",
            " [ 899   67]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.8030137414116177\n",
            "clf.score 0.7054965646470955 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.98      0.82      2236\n",
            "           1       0.59      0.08      0.13       966\n",
            "\n",
            "    accuracy                           0.71      3202\n",
            "   macro avg       0.65      0.53      0.48      3202\n",
            "weighted avg       0.67      0.71      0.61      3202\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[2186   50]\n",
            " [ 893   73]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.7973141786383511\n",
            "clf.score 0.7036227357901311 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.98      0.82      2236\n",
            "           1       0.57      0.07      0.13       966\n",
            "\n",
            "    accuracy                           0.70      3202\n",
            "   macro avg       0.64      0.52      0.47      3202\n",
            "weighted avg       0.67      0.70      0.61      3202\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[2184   52]\n",
            " [ 897   69]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwgYDYfzx8Y9",
        "colab_type": "code",
        "outputId": "a2d071b9-9ff0-4e81-f0b4-bee2d4ac9e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  x=df[['CustomerID','MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','PercChangeRevenues', 'PeakCallsInOut', 'OffPeakCallsInOut', 'MonthsInService', 'ServiceArea', 'CurrentEquipmentDays']]\n",
        "  y = df[['Churn']]\n",
        "  for i in range (0,5):\n",
        "    from sklearn.model_selection import train_test_split  \n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier(max_depth=80, n_estimators=350,min_samples_split=5, min_samples_leaf=5,bootstrap=False,max_features='sqrt')\n",
        "    clf.fit(xtrain,ytrain)\n",
        "    print(\"train score\",clf.score(xtrain, ytrain))\n",
        "    print('clf.score',clf.score(xtest, ytest),'\\n')\n",
        "    y_pred = clf.predict(xtest)\n",
        "    from sklearn.metrics import classification_report\n",
        "    print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.9844607458841975\n",
            "clf.score 0.7114392108185797 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.82     10880\n",
            "           1       0.50      0.13      0.21      4427\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.62      0.54      0.52     15307\n",
            "weighted avg       0.66      0.71      0.65     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10303   577]\n",
            " [ 3840   587]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.9834807929219398\n",
            "clf.score 0.7083033906056053 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.95      0.82     10770\n",
            "           1       0.53      0.13      0.21      4537\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.63      0.54      0.51     15307\n",
            "weighted avg       0.67      0.71      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10265   505]\n",
            " [ 3960   577]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.9839567700750363\n",
            "clf.score 0.7162082707258117 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.83     10889\n",
            "           1       0.53      0.14      0.22      4418\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.63      0.54      0.52     15307\n",
            "weighted avg       0.67      0.72      0.65     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10366   523]\n",
            " [ 3821   597]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.9848247284130361\n",
            "clf.score 0.7150323381459462 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.83     10889\n",
            "           1       0.53      0.13      0.20      4418\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.63      0.54      0.52     15307\n",
            "weighted avg       0.67      0.72      0.65     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10386   503]\n",
            " [ 3859   559]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.9835367902340688\n",
            "clf.score 0.7109819037041877 \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.82     10868\n",
            "           1       0.51      0.13      0.20      4439\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.62      0.54      0.51     15307\n",
            "weighted avg       0.66      0.71      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10313   555]\n",
            " [ 3869   570]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcE-tk2b2dGl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8f0ca6a5-910f-436e-a507-28517c856766",
        "id": "oRI8d3Hbz7k8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "x=df[['CustomerID','MonthlyRevenue','MonthlyMinutes','PercChangeMinutes','CurrentEquipmentDays']]\n",
        "y = df[['Churn']]\n",
        "for i in range(0,5):\n",
        "  from sklearn.model_selection import train_test_split  \n",
        "  xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  clf = RandomForestClassifier(max_depth=15, random_state=0,n_estimators=1000)\n",
        "  clf.fit(xtrain,ytrain)\n",
        "  print(\"train score\",clf.score(xtrain, ytrain))\n",
        "  print('clf.score',clf.score(xtest, ytest),'\\n')\n",
        "  y_pred = clf.predict(xtest)\n",
        "  from sklearn.metrics import precision_recall_fscore_support\n",
        "  print('precision_recall_fscore_support\\n',precision_recall_fscore_support(ytest, y_pred, average=None),'\\n')\n",
        "  from sklearn.metrics import classification_report\n",
        "  print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train score 0.7818904692574756\n",
            "clf.score 0.7162082707258117 \n",
            "\n",
            "precision_recall_fscore_support\n",
            " (array([0.72567393, 0.47586207]), array([0.97234101, 0.0639481 ]), array([0.83109106, 0.1127451 ]), array([10991,  4316])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83     10991\n",
            "           1       0.48      0.06      0.11      4316\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.60      0.52      0.47     15307\n",
            "weighted avg       0.66      0.72      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10687   304]\n",
            " [ 4040   276]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bcb52c5dfc7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf.score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ECALdbGdKr7",
        "colab_type": "code",
        "outputId": "12500476-2b81-49f1-c4e2-8dfbc9cc4d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomerID                     int64\n",
              "Churn                          int64\n",
              "MonthlyRevenue               float64\n",
              "MonthlyMinutes               float64\n",
              "TotalRecurringCharge         float64\n",
              "DirectorAssistedCalls        float64\n",
              "OverageMinutes               float64\n",
              "RoamingCalls                 float64\n",
              "PercChangeMinutes            float64\n",
              "PercChangeRevenues           float64\n",
              "DroppedCalls                 float64\n",
              "BlockedCalls                 float64\n",
              "UnansweredCalls              float64\n",
              "CustomerCareCalls            float64\n",
              "ThreewayCalls                float64\n",
              "ReceivedCalls                float64\n",
              "OutboundCalls                float64\n",
              "InboundCalls                 float64\n",
              "PeakCallsInOut               float64\n",
              "OffPeakCallsInOut            float64\n",
              "DroppedBlockedCalls          float64\n",
              "CallForwardingCalls          float64\n",
              "CallWaitingCalls             float64\n",
              "MonthsInService                int64\n",
              "UniqueSubs                     int64\n",
              "ActiveSubs                     int64\n",
              "ServiceArea                    int64\n",
              "Handsets                     float64\n",
              "HandsetModels                float64\n",
              "CurrentEquipmentDays         float64\n",
              "AgeHH1                       float64\n",
              "AgeHH2                       float64\n",
              "ChildrenInHH                   int64\n",
              "HandsetRefurbished             int64\n",
              "HandsetWebCapable              int64\n",
              "TruckOwner                     int64\n",
              "RVOwner                        int64\n",
              "Homeownership                  int64\n",
              "BuysViaMailOrder               int64\n",
              "RespondsToMailOffers           int64\n",
              "OptOutMailings                 int64\n",
              "NonUSTravel                    int64\n",
              "OwnsComputer                   int64\n",
              "HasCreditCard                  int64\n",
              "RetentionCalls                 int64\n",
              "RetentionOffersAccepted        int64\n",
              "NewCellphoneUser               int64\n",
              "NotNewCellphoneUser            int64\n",
              "ReferralsMadeBySubscriber      int64\n",
              "IncomeGroup                    int64\n",
              "OwnsMotorcycle                 int64\n",
              "AdjustmentsToCreditRating      int64\n",
              "HandsetPrice                   int64\n",
              "MadeCallToRetentionTeam        int64\n",
              "CreditRating                   int64\n",
              "PrizmCode                      int64\n",
              "Occupation                     int64\n",
              "MaritalStatus                  int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSHELPbvek8w",
        "colab_type": "code",
        "outputId": "0612c6d1-d854-4751-ebde-44c3ccd0780f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "xtrain.head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        CustomerID  MonthlyRevenue  ...  ServiceArea  CurrentEquipmentDays\n",
              "45796     3362334           46.77  ...          143                 257.0\n",
              "41551     3330934           34.87  ...          699                 310.0\n",
              "14260     3112282           52.08  ...          508                 453.0\n",
              "14551     3114534           24.99  ...          658                 748.0\n",
              "1462      3011486           35.24  ...          625                 423.0\n",
              "...           ...             ...  ...          ...                   ...\n",
              "9024      3071046           42.05  ...          154                   9.0\n",
              "12859     3101410           51.68  ...          455                 384.0\n",
              "43814     3347358           13.75  ...          387                 292.0\n",
              "36950     3294910           71.84  ...          436                 236.0\n",
              "6056      3047442           79.21  ...          358                 262.0\n",
              "\n",
              "[35716 rows x 10 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMYjSOfFoQwM",
        "colab_type": "code",
        "outputId": "1b8b416f-216c-47d6-cf48-3e0c5b10d266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "  #for i in range(0,5):\n",
        "    from sklearn.model_selection import train_test_split  \n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True,random_state=50)\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
        "    from sklearn.datasets import make_classification\n",
        "    #X, y = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=True)\n",
        "    dec_clf = DecisionTreeClassifier(max_depth=15)\n",
        "    ada_clf = AdaBoostClassifier(base_estimator=dec_clf,n_estimators=100,learning_rate=0.08)\n",
        "    ada_clf.fit(xtrain,ytrain)\n",
        "    print('training:',ada_clf.score(xtrain,ytrain))\n",
        "    print('test:',ada_clf.score(xtest,ytest))\n",
        "    y_pred = ada_clf.predict(xtest)\n",
        "    from sklearn.metrics import precision_recall_fscore_support\n",
        "    print('precision_recall_fscore_support\\n',precision_recall_fscore_support(ytest, y_pred, average=None),'\\n')\n",
        "    from sklearn.metrics import classification_report\n",
        "    print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training: 1.0\n",
            "test: 0.6914428482198626\n",
            "precision_recall_fscore_support\n",
            " (array([0.71480472, 0.43358396]), array([0.93301719, 0.12106368]), array([0.80946259, 0.1892779 ]), array([3374, 1429])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.93      0.81      3374\n",
            "           1       0.43      0.12      0.19      1429\n",
            "\n",
            "    accuracy                           0.69      4803\n",
            "   macro avg       0.57      0.53      0.50      4803\n",
            "weighted avg       0.63      0.69      0.62      4803\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[3148  226]\n",
            " [1256  173]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pdq31G8DgVA",
        "colab_type": "code",
        "outputId": "0e55de9c-4942-4e01-e1b2-1a9fb3c36b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "    from sklearn.model_selection import train_test_split  \n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
        "    from sklearn.datasets import make_classification\n",
        "    #X, y = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=True)\n",
        "    randm_ada = AdaBoostClassifier(RandomForestClassifier(max_depth=1),n_estimators=100, random_state=0,learning_rate=1.5,algorithm=\"SAMME\")\n",
        "    randm_ada.fit(xtrain,ytrain)\n",
        "    print('training:',randm_ada.score(xtrain,ytrain))\n",
        "    print('test:',randm_ada.score(xtest,ytest))    \n",
        "    y_pred = randm_ada.predict(xtest)\n",
        "    from sklearn.metrics import precision_recall_fscore_support\n",
        "    print('precision_recall_fscore_support\\n',precision_recall_fscore_support(ytest, y_pred, average=None),'\\n')\n",
        "    from sklearn.metrics import classification_report\n",
        "    print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training: 0.7150576772314929\n",
            "test: 0.7188214542366238\n",
            "precision_recall_fscore_support\n",
            " (array([0.729926  , 0.52948113]), array([0.96357162, 0.10312356]), array([0.8306312 , 0.17262591]), array([10953,  4354])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.96      0.83     10953\n",
            "           1       0.53      0.10      0.17      4354\n",
            "\n",
            "    accuracy                           0.72     15307\n",
            "   macro avg       0.63      0.53      0.50     15307\n",
            "weighted avg       0.67      0.72      0.64     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10554   399]\n",
            " [ 3905   449]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPbG6nfF2Imp",
        "colab_type": "code",
        "outputId": "db618195-62d1-4bec-dd92-2d8ab34a2069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split  \n",
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid={\n",
        "    'max_depth':[15],\n",
        "    'max_features':[3],\n",
        "    'n_estimators':[1000],\n",
        "    'min_samples_split':[4],\n",
        "    'bootstrap':[True]}\n",
        "grid_search = GridSearchCV(estimator = RandomForestClassifier(),param_grid=param_grid,cv=3,n_jobs=-1,verbose=2).fit(xtrain,ytrain)\n",
        "print('training:',grid_search.score(xtrain,ytrain))\n",
        "print('test:',grid_search.score(xtest,ytest))    \n",
        "y_pred = grid_search.predict(xtest)\n",
        "from sklearn.metrics import classification_report\n",
        "print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  2.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training: 0.8221525366782394\n",
            "test: 0.7147710197948651\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83     10848\n",
            "           1       0.57      0.08      0.14      4459\n",
            "\n",
            "    accuracy                           0.71     15307\n",
            "   macro avg       0.65      0.53      0.49     15307\n",
            "weighted avg       0.68      0.71      0.63     15307\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[10576   272]\n",
            " [ 4094   365]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX29rrKhwen4",
        "colab_type": "text"
      },
      "source": [
        "importing model to the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMF2z6Y4T0-U",
        "colab_type": "code",
        "outputId": "e8fa0447-7eb5-40da-d4a2-7f157fc8e4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "colors = [\"#0101DF\",\"#DF0101\"]\n",
        "sns.countplot('Churn',data = df,palette=colors)\n",
        "plt.title(\"chrun\\n(0 :No chrun||1: chrun)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'chrun\\n(0 :No chrun||1: chrun)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAF1CAYAAADiLzM9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMAQhD4AAIYg9AEAMMT/AzI4pfLVeErOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMAGUkfOZmtu",
        "colab_type": "code",
        "outputId": "db6d8b15-1fab-4f06-fde4-153e748f06d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "roc_auc\n",
        "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
        "train_results = []\n",
        "test_results = []\n",
        "from sklearn.model_selection import train_test_split  \n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "for estimator in n_estimators:\n",
        "   randm_ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=100, random_state=0,learning_rate=1.5,algorithm=\"SAMME\")\n",
        "   randm_ada.fit(x_train,y_train)\n",
        "   train_pred = randm_ada.predict(x_train)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = randm_ada.predict(x_test)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1 = plt.plot(n_estimators, train_results, \"b\", label =\"Train AUC\")\n",
        "line2 = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('AUC score')\n",
        "plt.xlabel('n_estimators')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-e067c2457a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mline1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"Train AUC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mline2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test AUC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mline1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHandlerLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhiDaAAAY4v8AuOVnuuVDSTkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbRydFWJoKwi",
        "colab_type": "code",
        "outputId": "17d9f59d-8525-4d80-bac4-d428752524f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Churn</th>\n",
              "      <th>MonthlyRevenue</th>\n",
              "      <th>MonthlyMinutes</th>\n",
              "      <th>TotalRecurringCharge</th>\n",
              "      <th>DirectorAssistedCalls</th>\n",
              "      <th>OverageMinutes</th>\n",
              "      <th>RoamingCalls</th>\n",
              "      <th>PercChangeMinutes</th>\n",
              "      <th>PercChangeRevenues</th>\n",
              "      <th>DroppedCalls</th>\n",
              "      <th>BlockedCalls</th>\n",
              "      <th>UnansweredCalls</th>\n",
              "      <th>CustomerCareCalls</th>\n",
              "      <th>ThreewayCalls</th>\n",
              "      <th>ReceivedCalls</th>\n",
              "      <th>OutboundCalls</th>\n",
              "      <th>InboundCalls</th>\n",
              "      <th>PeakCallsInOut</th>\n",
              "      <th>OffPeakCallsInOut</th>\n",
              "      <th>DroppedBlockedCalls</th>\n",
              "      <th>CallForwardingCalls</th>\n",
              "      <th>CallWaitingCalls</th>\n",
              "      <th>MonthsInService</th>\n",
              "      <th>UniqueSubs</th>\n",
              "      <th>ActiveSubs</th>\n",
              "      <th>ServiceArea</th>\n",
              "      <th>Handsets</th>\n",
              "      <th>HandsetModels</th>\n",
              "      <th>CurrentEquipmentDays</th>\n",
              "      <th>AgeHH1</th>\n",
              "      <th>AgeHH2</th>\n",
              "      <th>ChildrenInHH</th>\n",
              "      <th>HandsetRefurbished</th>\n",
              "      <th>HandsetWebCapable</th>\n",
              "      <th>TruckOwner</th>\n",
              "      <th>RVOwner</th>\n",
              "      <th>Homeownership</th>\n",
              "      <th>BuysViaMailOrder</th>\n",
              "      <th>RespondsToMailOffers</th>\n",
              "      <th>OptOutMailings</th>\n",
              "      <th>NonUSTravel</th>\n",
              "      <th>OwnsComputer</th>\n",
              "      <th>HasCreditCard</th>\n",
              "      <th>RetentionCalls</th>\n",
              "      <th>RetentionOffersAccepted</th>\n",
              "      <th>NewCellphoneUser</th>\n",
              "      <th>NotNewCellphoneUser</th>\n",
              "      <th>ReferralsMadeBySubscriber</th>\n",
              "      <th>IncomeGroup</th>\n",
              "      <th>OwnsMotorcycle</th>\n",
              "      <th>AdjustmentsToCreditRating</th>\n",
              "      <th>HandsetPrice</th>\n",
              "      <th>MadeCallToRetentionTeam</th>\n",
              "      <th>CreditRating</th>\n",
              "      <th>PrizmCode</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>MaritalStatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.102300e+04</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "      <td>51023.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.201981e+06</td>\n",
              "      <td>0.288086</td>\n",
              "      <td>58.831616</td>\n",
              "      <td>525.598983</td>\n",
              "      <td>46.830028</td>\n",
              "      <td>0.895034</td>\n",
              "      <td>40.022153</td>\n",
              "      <td>1.236432</td>\n",
              "      <td>-11.581171</td>\n",
              "      <td>-1.199317</td>\n",
              "      <td>6.010944</td>\n",
              "      <td>4.083913</td>\n",
              "      <td>28.288313</td>\n",
              "      <td>1.867489</td>\n",
              "      <td>0.298832</td>\n",
              "      <td>114.785120</td>\n",
              "      <td>25.371221</td>\n",
              "      <td>8.177226</td>\n",
              "      <td>90.548935</td>\n",
              "      <td>67.635018</td>\n",
              "      <td>10.155714</td>\n",
              "      <td>0.012283</td>\n",
              "      <td>1.840384</td>\n",
              "      <td>18.756600</td>\n",
              "      <td>1.531937</td>\n",
              "      <td>1.354174</td>\n",
              "      <td>351.533700</td>\n",
              "      <td>1.805692</td>\n",
              "      <td>1.558818</td>\n",
              "      <td>380.564991</td>\n",
              "      <td>31.334523</td>\n",
              "      <td>21.141231</td>\n",
              "      <td>0.242165</td>\n",
              "      <td>0.138898</td>\n",
              "      <td>0.902025</td>\n",
              "      <td>0.186406</td>\n",
              "      <td>0.081257</td>\n",
              "      <td>0.334281</td>\n",
              "      <td>0.361386</td>\n",
              "      <td>0.376575</td>\n",
              "      <td>0.014738</td>\n",
              "      <td>0.056406</td>\n",
              "      <td>0.185348</td>\n",
              "      <td>0.675813</td>\n",
              "      <td>0.037199</td>\n",
              "      <td>0.018266</td>\n",
              "      <td>0.192403</td>\n",
              "      <td>0.137801</td>\n",
              "      <td>0.052094</td>\n",
              "      <td>4.323874</td>\n",
              "      <td>0.013288</td>\n",
              "      <td>0.053936</td>\n",
              "      <td>11.193717</td>\n",
              "      <td>0.034181</td>\n",
              "      <td>1.887267</td>\n",
              "      <td>1.135233</td>\n",
              "      <td>3.161025</td>\n",
              "      <td>1.116555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.169140e+05</td>\n",
              "      <td>0.452876</td>\n",
              "      <td>44.441046</td>\n",
              "      <td>529.061843</td>\n",
              "      <td>23.812641</td>\n",
              "      <td>2.224956</td>\n",
              "      <td>96.451972</td>\n",
              "      <td>9.805417</td>\n",
              "      <td>256.601528</td>\n",
              "      <td>39.431917</td>\n",
              "      <td>9.044773</td>\n",
              "      <td>10.945340</td>\n",
              "      <td>38.879473</td>\n",
              "      <td>5.086508</td>\n",
              "      <td>1.168514</td>\n",
              "      <td>166.490255</td>\n",
              "      <td>35.202964</td>\n",
              "      <td>16.667845</td>\n",
              "      <td>104.963265</td>\n",
              "      <td>92.745247</td>\n",
              "      <td>15.554445</td>\n",
              "      <td>0.594308</td>\n",
              "      <td>5.585892</td>\n",
              "      <td>9.801269</td>\n",
              "      <td>1.223341</td>\n",
              "      <td>0.675230</td>\n",
              "      <td>203.854534</td>\n",
              "      <td>1.331317</td>\n",
              "      <td>0.906046</td>\n",
              "      <td>253.820101</td>\n",
              "      <td>21.899673</td>\n",
              "      <td>23.718128</td>\n",
              "      <td>0.428398</td>\n",
              "      <td>0.345844</td>\n",
              "      <td>0.297284</td>\n",
              "      <td>0.389438</td>\n",
              "      <td>0.273233</td>\n",
              "      <td>0.471743</td>\n",
              "      <td>0.480407</td>\n",
              "      <td>0.484532</td>\n",
              "      <td>0.120505</td>\n",
              "      <td>0.230706</td>\n",
              "      <td>0.388583</td>\n",
              "      <td>0.468075</td>\n",
              "      <td>0.206486</td>\n",
              "      <td>0.142425</td>\n",
              "      <td>0.394192</td>\n",
              "      <td>0.344694</td>\n",
              "      <td>0.307662</td>\n",
              "      <td>3.138366</td>\n",
              "      <td>0.114507</td>\n",
              "      <td>0.383235</td>\n",
              "      <td>5.218628</td>\n",
              "      <td>0.181695</td>\n",
              "      <td>1.583520</td>\n",
              "      <td>1.174855</td>\n",
              "      <td>0.879260</td>\n",
              "      <td>0.774858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000002e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-6.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-11.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3875.000000</td>\n",
              "      <td>-1107.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.100632e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.660000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-82.000000</td>\n",
              "      <td>-6.900000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.201586e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.620000</td>\n",
              "      <td>368.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>-0.300000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.700000</td>\n",
              "      <td>13.700000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>35.700000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>329.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.305422e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>70.960000</td>\n",
              "      <td>722.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>40.027785</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>36.300000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>153.500000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>121.300000</td>\n",
              "      <td>88.700000</td>\n",
              "      <td>12.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>481.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>515.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.399994e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1223.380000</td>\n",
              "      <td>7359.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>159.390000</td>\n",
              "      <td>4321.000000</td>\n",
              "      <td>1112.400000</td>\n",
              "      <td>5192.000000</td>\n",
              "      <td>2483.500000</td>\n",
              "      <td>221.700000</td>\n",
              "      <td>384.300000</td>\n",
              "      <td>848.700000</td>\n",
              "      <td>327.300000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>2692.400000</td>\n",
              "      <td>644.300000</td>\n",
              "      <td>519.300000</td>\n",
              "      <td>2090.700000</td>\n",
              "      <td>1474.700000</td>\n",
              "      <td>411.700000</td>\n",
              "      <td>81.300000</td>\n",
              "      <td>212.700000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>196.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>746.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1812.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         CustomerID         Churn  ...    Occupation  MaritalStatus\n",
              "count  5.102300e+04  51023.000000  ...  51023.000000   51023.000000\n",
              "mean   3.201981e+06      0.288086  ...      3.161025       1.116555\n",
              "std    1.169140e+05      0.452876  ...      0.879260       0.774858\n",
              "min    3.000002e+06      0.000000  ...      0.000000       0.000000\n",
              "25%    3.100632e+06      0.000000  ...      3.000000       1.000000\n",
              "50%    3.201586e+06      0.000000  ...      3.000000       1.000000\n",
              "75%    3.305422e+06      1.000000  ...      3.000000       2.000000\n",
              "max    3.399994e+06      1.000000  ...      7.000000       2.000000\n",
              "\n",
              "[8 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC7TuqfoFy9r",
        "colab_type": "code",
        "outputId": "ff60d206-21f9-45c9-d9d0-7b93e93661ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "  #for i in range(0,5):\n",
        "    from sklearn.model_selection import train_test_split  \n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
        "    from sklearn.datasets import make_classification\n",
        "    #X, y = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=True)\n",
        "    dec_clf = DecisionTreeClassifier()\n",
        "    ada_clf = AdaBoostClassifier(base_estimator=dec_clf)\n",
        "    ada_clf.fit(xtrain,ytrain)\n",
        "    print('training:',ada_clf.score(xtrain,ytrain))\n",
        "    print('test:',ada_clf.score(xtest,ytest))\n",
        "    y_pred = ada_clf.predict(xtest)\n",
        "    from sklearn.metrics import precision_recall_fscore_support\n",
        "    print('precision_recall_fscore_support\\n',precision_recall_fscore_support(ytest, y_pred, average=None),'\\n')\n",
        "    from sklearn.metrics import classification_report\n",
        "    print('classification_report',classification_report(ytest,y_pred),'\\n')\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training: 1.0\n",
            "test: 0.6202800169707255\n",
            "precision_recall_fscore_support\n",
            " (array([0.73602854, 0.33185185]), array([0.73297809, 0.33532934]), array([0.73450015, 0.33358153]), array([3378, 1336])) \n",
            "\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.73      0.73      3378\n",
            "           1       0.33      0.34      0.33      1336\n",
            "\n",
            "    accuracy                           0.62      4714\n",
            "   macro avg       0.53      0.53      0.53      4714\n",
            "weighted avg       0.62      0.62      0.62      4714\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[2476  902]\n",
            " [ 888  448]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlpRe_4ZJI3t",
        "colab_type": "code",
        "outputId": "8286fcc1-5baa-4b43-9f75-b1d0dafa7a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,shuffle=True)\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=3, random_state=0).fit(xtrain, ytrain)\n",
        "print('Accuracy of training set: ',gb_model.score(xtrain, ytrain))\n",
        "print('Accuracy of test set: ',gb_model.score(xtest, ytest))\n",
        "y_pred = gb_model.predict(xtest)\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print('precision_recall_fscore_support\\n',precision_recall_fscore_support(ytest, y_pred, average=None),'\\n')\n",
        "from sklearn.metrics import classification_report\n",
        "print('classification_report\\n',classification_report(ytest,y_pred),'\\n')\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('confusion_matrix\\n',confusion_matrix(ytest,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of training set:  0.7362917159225243\n",
            "Accuracy of test set:  0.7093763258379295\n",
            "precision_recall_fscore_support\n",
            " (array([0.71506431, 0.50393701]), array([0.98115465, 0.04668125]), array([0.82723834, 0.08544726]), array([3343, 1371])) \n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83      3343\n",
            "           1       0.50      0.05      0.09      1371\n",
            "\n",
            "    accuracy                           0.71      4714\n",
            "   macro avg       0.61      0.51      0.46      4714\n",
            "weighted avg       0.65      0.71      0.61      4714\n",
            " \n",
            "\n",
            "confusion_matrix\n",
            " [[3280   63]\n",
            " [1307   64]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcFyDtpOsYlW",
        "colab_type": "text"
      },
      "source": [
        "***Voting Classifier***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqHDdUmZsW5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}